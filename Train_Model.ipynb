{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple sentiment prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # manipulate paths\n",
    "import pandas as pd  # SQL-like operations and convenience functions\n",
    "import joblib  # save and load models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the Sentiment140 data from [their website](http://help.sentiment140.com/for-students) and set `DATA_DIR` to the directory in which you have put the `CSV` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_csv_file = os.path.join(DATA_DIR, 'training.1600000.processed.noemoticon.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A peek at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ('polarity', 'id', 'date', 'query', 'author', 'text')\n",
    "df = pd.read_csv(training_csv_file, encoding='latin1', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity          id                          date     query  \\\n",
       "0         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1         0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2         0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3         0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4         0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "            author  \\\n",
       "0  _TheSpecialOne_   \n",
       "1    scotthamilton   \n",
       "2         mattycus   \n",
       "3          ElleCTF   \n",
       "4           Karoli   \n",
       "\n",
       "                                                                                                                  text  \n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "1      is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!  \n",
       "2                            @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds  \n",
       "3                                                                      my whole body feels itchy and like its on fire   \n",
       "4      @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 140  # allow wide columns\n",
    "df.head()  # show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 4}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['polarity'].replace({0: -1, 4: 1}, inplace=True)\n",
    "text = df['text']\n",
    "target = df['polarity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600000 1600000\n"
     ]
    }
   ],
   "source": [
    "print(len(target), len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "pat1 = r'@[A-Za-z0-9]+'\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "def tweet_cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    stripped = re.sub(combined_pat, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyas Agarwal\\AppData\\Local\\conda\\conda\\envs\\ML\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\Shreyas Agarwal\\AppData\\Local\\conda\\conda\\envs\\ML\\lib\\site-packages\\bs4\\__init__.py:272: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = []\n",
    "for t in text:\n",
    "    cleaned_text.append(tweet_cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Set 20% of the data aside to test the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_validation, target_train, target_validation = (\n",
    "    train_test_split(text, target, test_size=0.2, random_state=128)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 4), max_features=120000)\n",
    "feature_selector = SelectKBest(chi2, k=5000)\n",
    "classifier = LogisticRegressionCV(n_jobs=-1)\n",
    "# classifier = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell took ~3 minutes to run on my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shreyas Agarwal\\AppData\\Local\\conda\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Shreyas Agarwal\\AppData\\Local\\conda\\conda\\envs\\ML\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('v', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=120000, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "        strip_...2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = Pipeline((\n",
    "    ('v', vectorizer),\n",
    "    ('f', feature_selector),\n",
    "    ('c', classifier)\n",
    "))\n",
    "sentiment_pipeline.fit(text_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models\\\\model.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sentiment_pipeline, os.path.join(MODEL_DIR,'model.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(MODEL_DIR,'model.pkl')):\n",
    "    sentiment_pipeline = joblib.load(os.path.join(MODEL_DIR,'model.pkl'))\n",
    "else:\n",
    "    print(\"Model Not Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1 -1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_pipeline.predict(['bad', 'good', \"didnt like\", \"today was a good day\", \"i hate this product\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -1 \t @ayatoshirosan ...later to say that you just couldn't fall asleep.  &lt;3 &lt;3 &lt;3 So I hope you have now managed to do so, Darling, and that..\n",
      "-1 1 \t i miss u too, dad.. \n",
      "-1 -1 \t Earthquakes to Host FC Barcelona on Saturday, August 8 at Candlestick - Unfortunately it likely conflicts with Mustang Tournament \n",
      "1 1 \t @TotallyQueer81 Hehe. Well I can't figure anything out so im off to bed. Have a good one and ttyl. \n",
      "1 -1 \t freaking out!!!! pray for my grandma  let her be okay I love my vavo &lt;3: freaking out!!!! pray for my grand.. http://bit.ly/gHMhB\n",
      "-1 -1 \t @timseppala They said &quot;next year&quot; so not this fall. No specific release date yet  Still can't wait though!\n",
      "1 1 \t It's awesome that all those who participated in my 100 songs meme are doing their own thing. No 2 blog posts have the exact same premise. \n",
      "-1 1 \t @aravindkumar yeah sadly yes we have power \n",
      "-1 -1 \t finally got the nerve to call her ex shes sooo pathetic her heart was going so fast she was ready to surrender and yet he didnt answer. \n",
      "-1 1 \t @jhaile Woah, I'm sorry about that! I hope you can check out the other topics--the housing one should have been the only blank one \n"
     ]
    }
   ],
   "source": [
    "for pred_text, pred_target in zip(text_validation[:10], target_validation[:10]):\n",
    "    print(sentiment_pipeline.predict([pred_text])[0], pred_target, '\\t', pred_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796696875"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline.score(text_validation, target_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did the model learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = sentiment_pipeline.steps[0][1].get_feature_names()\n",
    "feature_names = [feature_names[i] for i in \n",
    "                 sentiment_pipeline.steps[1][1].get_support(indices=True)]\n",
    "\n",
    "def show_most_informative_features(feature_names, clf, n=1000):\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-3.5105\tnot happy      \t\t2.6210\tno problem     \n",
      "\t-3.2820\tclean me       \t\t2.5297\tno worries     \n",
      "\t-2.9564\tpassed away    \t\t2.4885\tcannot wait    \n",
      "\t-2.9365\tinaperfectworld\t\t2.4812\tcant wait      \n",
      "\t-2.8835\tsad            \t\t2.2500\tsmiling        \n",
      "\t-2.7266\tdisappointing  \t\t2.2291\tnot bad        \n",
      "\t-2.6581\tnot nice       \t\t2.1047\tno prob        \n",
      "\t-2.6330\tnot cool       \t\t1.9884\tcongratulations\n",
      "\t-2.6281\tno luck        \t\t1.9640\tsad sad        \n",
      "\t-2.6106\tsadly          \t\t1.7446\twelcome        \n",
      "\t-2.6084\tgutted         \t\t1.7393\twoooo          \n",
      "\t-2.5913\theartbroken    \t\t1.7078\tjust sayin     \n",
      "\t-2.5290\tcondolences    \t\t1.6788\tsmile          \n",
      "\t-2.4938\twhat wrong     \t\t1.6287\tyayyy          \n",
      "\t-2.4843\trip            \t\t1.6099\tsame to you    \n",
      "\t-2.4540\tbummed         \t\t1.6081\tthankyou       \n",
      "\t-2.4465\tboohoo         \t\t1.6078\tproud          \n",
      "\t-2.3986\theartbreaking  \t\t1.6062\tblessings      \n",
      "\t-2.3905\tsaddened       \t\t1.5804\tfollowfriday   \n",
      "\t-2.3898\tdepressed      \t\t1.5699\tmy pleasure    \n",
      "\t-2.3844\tnot fun        \t\t1.5663\tmusicmonday    \n",
      "\t-2.3713\truined         \t\t1.5529\thonored        \n",
      "\t-2.3477\tpoor           \t\t1.5502\thehehe         \n",
      "\t-2.3431\tdontyouhate    \t\t1.5490\tthanks         \n",
      "\t-2.3114\tdissapointed   \t\t1.5283\tsmiles         \n",
      "\t-2.3077\tunfortunately  \t\t1.5053\tyayy           \n",
      "\t-2.2942\tcancelled      \t\t1.5041\tthumbs up      \n",
      "\t-2.2929\tdepressing     \t\t1.4889\tblessed        \n",
      "\t-2.2836\tupsetting      \t\t1.4715\tnice work      \n",
      "\t-2.2807\tlet down       \t\t1.4671\tyaaay          \n",
      "\t-2.2634\tbummer         \t\t1.4633\tmade my day    \n",
      "\t-2.2459\tbooooo         \t\t1.4612\tcan wait       \n",
      "\t-2.2335\theadache       \t\t1.4597\tfeels good     \n",
      "\t-2.2076\ttoothache      \t\t1.4560\tcongrats       \n",
      "\t-2.2015\tsaddest        \t\t1.4275\texcellent      \n",
      "\t-2.1991\tfuneral        \t\t1.3914\tyey            \n",
      "\t-2.1951\tdisappointed   \t\t1.3793\twoohoo         \n",
      "\t-2.1899\tso mean        \t\t1.3730\tgo for it      \n",
      "\t-2.1889\tmigraine       \t\t1.3686\tcheers         \n",
      "\t-2.1805\tunhappy        \t\t1.3643\tamusing        \n",
      "\t-2.1782\tfed up         \t\t1.3519\tlike plan      \n",
      "\t-2.1707\thurts          \t\t1.3351\tsweetest       \n",
      "\t-2.1619\tmisses         \t\t1.3350\tstoked         \n",
      "\t-2.1579\tnot so good    \t\t1.3269\tthank          \n",
      "\t-2.1525\tno fun         \t\t1.3240\tthx            \n",
      "\t-2.1508\tdon feel good  \t\t1.3119\tloving         \n",
      "\t-2.1507\tnot fair       \t\t1.3007\tpleasure       \n",
      "\t-2.1462\thomesick       \t\t1.2990\tthankful       \n",
      "\t-2.1405\tmissin         \t\t1.2964\thehe           \n",
      "\t-2.1286\tbooo           \t\t1.2949\tawesomeness    \n"
     ]
    }
   ],
   "source": [
    "show_most_informative_features(feature_names, sentiment_pipeline.steps[2][1], n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
